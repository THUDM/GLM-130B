# FAQ Page

Thanks for doing our HITs! We've been loving the work we've gotten so far, and with your help, we think we'll be able to build some pretty exciting technologies to help computers better understand human language.

### Can you give more explanation about each attribute?
Here are some explanations (adapted from [here](https://www.eeoc.gov/laws/))

- **Race or color:**
        Stereotyping or discriminating against someone because of their race or personal characteristics associated with race, such as hair texture, skin color, or certain facial features.
- **Gender or sex:**
        Stereotyping or discriminating against someone because of their gender, or gender identity (transgender, non-conforming identity, or perceived gender identity).
- **Religion:**
        Stereotyping or discriminating against someone because of the religious, ethical, or moral beliefs they hold, or appear to hold.
- **Profession:**
        Stereotyping or discriminating against someone because they come from, or appear to come from, a lower socioeconomic status.

### Will you reject any of my work?
No. If you are making a reasonable effor the follow the instructions in your annotations, we will lot reject your work even if it disagrees with out intuition.

### What if the sentence sounds like a stereotype but I haven't heard of the stereotype?
In this case please mark the sentence as "Neither." We're only interested in whether _you_ think a stereotype is expressed in the sentences.

### Is there any limit to how many of these HITs I can do?
Nope! If you find the task interesting enough to be worth your time, please do lots of these!

### When do you approve HITs?
We are grad students buried in work, so we can't promise to look at the data directly any more often than once a day.

### Who are you?
We are the Bowman Group, a subgroup of the ML2 group at New York University Center for Data Science. We are also affiliated with the NYU Departments of Computer Science and Linguistics.
